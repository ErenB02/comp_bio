{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ErenB02/comp_bio/blob/main/CS6405_CS3033_2425_Assignment2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CS3033/CS6405 - Data Mining - Second Assignment\n",
        "\n",
        "Eren Boybay - 120446946 - CS6405\n",
        "\n",
        "### Submission\n",
        "\n",
        "You should submit a single .ipnyb file with your python code and analysis electronically via Canvas. Please note that this assignment will account for 25 Marks of your module grade.\n",
        "\n",
        "\n",
        "### Declaration\n",
        "\n",
        "By submitting this assignment. I agree to the following:\n",
        "\n",
        "<font color=\"red\">“I have read and understand the UCC academic policy on plagiarism, and agree to the requirements set out thereby in relation to plagiarism and referencing. I confirm that I have referenced and acknowledged properly all sources used in the preparation of this assignment.\n",
        "I declare that this assignment is entirely my own work based on my personal study. I further declare that I have not engaged the services of another to either assist me in, or complete this assignment”</font>Physical fatigue significantly impacts performance, safety, and health in domains such as sports, rehabilitation, and workplace ergonomics. Traditional methods for estimating fatigue, such as subjective self-reports, often lack accuracy and real-time applicability. Leveraging wearable sensors like Inertial Measurement Units (IMU) and Electromyography (EMG) provides objective biomechanical data, capturing kinematic and neuromuscular changes during repetitive or prolonged physical activities.\n",
        "\n",
        "The provided dataset was collected from 27 physically active participants performing shoulder internal rotation (IR) and external rotation (ER) exercises at varying resistance levels (30-40%, 40-50%, and 50-60% of their maximal voluntary contraction).\n",
        "Your task is to develop a regression-based machine learning model to estimate perceived fatigue (Borg RPE scores) using the provided sensor data."
      ],
      "metadata": {
        "id": "8WfrCFmLHxYu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preparation"
      ],
      "metadata": {
        "id": "Oav9G1WSJ1nH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "file_id = '1DP3G49DWVUaRBkn7wssPi6CfY1pTmTQP'\n",
        "url = f'https://drive.google.com/uc?id={file_id}'\n",
        "\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "DE0kM0QsJ1En",
        "outputId": "e1dbd656-7685-45eb-e679-d5f26e16d048"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Subject  Repetition  X_Shoulder_acc_MPSD  X_Shoulder_acc_Freq_MPSD  \\\n",
              "0        1           1             2068.313                     0.000   \n",
              "1        1           2              150.884                     0.699   \n",
              "2        1           3              342.205                     0.000   \n",
              "3        1           4              574.134                     0.000   \n",
              "4        1           5              146.332                     1.993   \n",
              "\n",
              "   X_Shoulder_acc_Power_Dominant_Band  X_Shoulder_acc_Ratio_Dominant_Band  \\\n",
              "0                               0.000                               0.000   \n",
              "1                             150.884                               0.183   \n",
              "2                               0.000                               0.000   \n",
              "3                               0.000                               0.000   \n",
              "4                             146.332                               0.123   \n",
              "\n",
              "   X_Shoulder_acc_Total_LowFreq_Power  X_Shoulder_acc_Total_HighFreq_Power  \\\n",
              "0                            2318.602                              154.645   \n",
              "1                             503.764                              322.154   \n",
              "2                             862.122                              197.057   \n",
              "3                            1007.744                              195.604   \n",
              "4                             826.328                              364.276   \n",
              "\n",
              "   X_Shoulder_acc_LowHigh_FreqRatio  X_Shoulder_acc_Total_Power  ...  \\\n",
              "0                            14.993                    2473.247  ...   \n",
              "1                             1.564                     825.919  ...   \n",
              "2                             4.375                    1059.179  ...   \n",
              "3                             5.152                    1203.347  ...   \n",
              "4                             2.268                    1190.603  ...   \n",
              "\n",
              "   Magnitude_Palm_gyr_rtVar_Max  Magnitude_Palm_gyr_rtVar_Min  \\\n",
              "0                         0.153                        -0.170   \n",
              "1                         0.148                        -0.196   \n",
              "2                         0.104                        -0.107   \n",
              "3                         0.149                        -0.177   \n",
              "4                         0.160                        -0.197   \n",
              "\n",
              "   Magnitude_Palm_gyr_rtVar_Range  Magnitude_Palm_gyr_rtVar_RMS  \\\n",
              "0                           0.324                         0.051   \n",
              "1                           0.344                         0.056   \n",
              "2                           0.211                         0.040   \n",
              "3                           0.325                         0.056   \n",
              "4                           0.357                         0.058   \n",
              "\n",
              "   Magnitude_Palm_gyr_rtVar_Energy  Magnitude_Palm_gyr_rtVar_IQR  \\\n",
              "0                            0.797                         0.059   \n",
              "1                            0.892                         0.064   \n",
              "2                            0.479                         0.051   \n",
              "3                            0.908                         0.069   \n",
              "4                            1.018                         0.069   \n",
              "\n",
              "   Magnitude_Palm_gyr_rtVar_Skewness  Magnitude_Palm_gyr_rtVar_Kurtosis  \\\n",
              "0                             -0.465                              1.233   \n",
              "1                             -0.184                              0.645   \n",
              "2                              0.007                              0.133   \n",
              "3                             -0.240                              0.136   \n",
              "4                             -0.144                              0.439   \n",
              "\n",
              "   RepetitionDuration_Palm_gyr_rtVar    Borg  \n",
              "0                               3.10   9.355  \n",
              "1                               2.86   9.653  \n",
              "2                               2.99   9.946  \n",
              "3                               2.91  10.240  \n",
              "4                               3.01  10.536  \n",
              "\n",
              "[5 rows x 2173 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-47a907bf-96cc-49b9-8272-c49d4cfdb159\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Subject</th>\n",
              "      <th>Repetition</th>\n",
              "      <th>X_Shoulder_acc_MPSD</th>\n",
              "      <th>X_Shoulder_acc_Freq_MPSD</th>\n",
              "      <th>X_Shoulder_acc_Power_Dominant_Band</th>\n",
              "      <th>X_Shoulder_acc_Ratio_Dominant_Band</th>\n",
              "      <th>X_Shoulder_acc_Total_LowFreq_Power</th>\n",
              "      <th>X_Shoulder_acc_Total_HighFreq_Power</th>\n",
              "      <th>X_Shoulder_acc_LowHigh_FreqRatio</th>\n",
              "      <th>X_Shoulder_acc_Total_Power</th>\n",
              "      <th>...</th>\n",
              "      <th>Magnitude_Palm_gyr_rtVar_Max</th>\n",
              "      <th>Magnitude_Palm_gyr_rtVar_Min</th>\n",
              "      <th>Magnitude_Palm_gyr_rtVar_Range</th>\n",
              "      <th>Magnitude_Palm_gyr_rtVar_RMS</th>\n",
              "      <th>Magnitude_Palm_gyr_rtVar_Energy</th>\n",
              "      <th>Magnitude_Palm_gyr_rtVar_IQR</th>\n",
              "      <th>Magnitude_Palm_gyr_rtVar_Skewness</th>\n",
              "      <th>Magnitude_Palm_gyr_rtVar_Kurtosis</th>\n",
              "      <th>RepetitionDuration_Palm_gyr_rtVar</th>\n",
              "      <th>Borg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2068.313</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>2318.602</td>\n",
              "      <td>154.645</td>\n",
              "      <td>14.993</td>\n",
              "      <td>2473.247</td>\n",
              "      <td>...</td>\n",
              "      <td>0.153</td>\n",
              "      <td>-0.170</td>\n",
              "      <td>0.324</td>\n",
              "      <td>0.051</td>\n",
              "      <td>0.797</td>\n",
              "      <td>0.059</td>\n",
              "      <td>-0.465</td>\n",
              "      <td>1.233</td>\n",
              "      <td>3.10</td>\n",
              "      <td>9.355</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>150.884</td>\n",
              "      <td>0.699</td>\n",
              "      <td>150.884</td>\n",
              "      <td>0.183</td>\n",
              "      <td>503.764</td>\n",
              "      <td>322.154</td>\n",
              "      <td>1.564</td>\n",
              "      <td>825.919</td>\n",
              "      <td>...</td>\n",
              "      <td>0.148</td>\n",
              "      <td>-0.196</td>\n",
              "      <td>0.344</td>\n",
              "      <td>0.056</td>\n",
              "      <td>0.892</td>\n",
              "      <td>0.064</td>\n",
              "      <td>-0.184</td>\n",
              "      <td>0.645</td>\n",
              "      <td>2.86</td>\n",
              "      <td>9.653</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>342.205</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>862.122</td>\n",
              "      <td>197.057</td>\n",
              "      <td>4.375</td>\n",
              "      <td>1059.179</td>\n",
              "      <td>...</td>\n",
              "      <td>0.104</td>\n",
              "      <td>-0.107</td>\n",
              "      <td>0.211</td>\n",
              "      <td>0.040</td>\n",
              "      <td>0.479</td>\n",
              "      <td>0.051</td>\n",
              "      <td>0.007</td>\n",
              "      <td>0.133</td>\n",
              "      <td>2.99</td>\n",
              "      <td>9.946</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>574.134</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1007.744</td>\n",
              "      <td>195.604</td>\n",
              "      <td>5.152</td>\n",
              "      <td>1203.347</td>\n",
              "      <td>...</td>\n",
              "      <td>0.149</td>\n",
              "      <td>-0.177</td>\n",
              "      <td>0.325</td>\n",
              "      <td>0.056</td>\n",
              "      <td>0.908</td>\n",
              "      <td>0.069</td>\n",
              "      <td>-0.240</td>\n",
              "      <td>0.136</td>\n",
              "      <td>2.91</td>\n",
              "      <td>10.240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>146.332</td>\n",
              "      <td>1.993</td>\n",
              "      <td>146.332</td>\n",
              "      <td>0.123</td>\n",
              "      <td>826.328</td>\n",
              "      <td>364.276</td>\n",
              "      <td>2.268</td>\n",
              "      <td>1190.603</td>\n",
              "      <td>...</td>\n",
              "      <td>0.160</td>\n",
              "      <td>-0.197</td>\n",
              "      <td>0.357</td>\n",
              "      <td>0.058</td>\n",
              "      <td>1.018</td>\n",
              "      <td>0.069</td>\n",
              "      <td>-0.144</td>\n",
              "      <td>0.439</td>\n",
              "      <td>3.01</td>\n",
              "      <td>10.536</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 2173 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-47a907bf-96cc-49b9-8272-c49d4cfdb159')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-47a907bf-96cc-49b9-8272-c49d4cfdb159 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-47a907bf-96cc-49b9-8272-c49d4cfdb159');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-fd45a839-0794-48f2-b910-adbab9d34728\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fd45a839-0794-48f2-b910-adbab9d34728')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-fd45a839-0794-48f2-b910-adbab9d34728 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Label or target variable\n",
        "df['Borg'].plot.box()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "N8MCvTYTKw4Q",
        "outputId": "2de88c78-c952-4243-a2e1-f9cc4f97bb8f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "metadata": {},
          "execution_count": 2
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tasks\n",
        "\n",
        "## Basic models and evaluation\n",
        "\n",
        "Using Scikit-learn, train and evaluate K-NN and decision tree regressors using 70% of the dataset from training and 30% for testing. For this part of the project, we are not interested in optimising the parameters; we just want to get an idea of the dataset.\n",
        "Compare the results of both classifiers and comment on their execution time in the test.\n"
      ],
      "metadata": {
        "id": "MTvkBPQvITf-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE\n",
        "from sklearn import neighbors\n",
        "from sklearn import tree\n",
        "from sklearn import metrics\n",
        "from sklearn import model_selection\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "#First we extract the features and label\n",
        "X = df.loc[:, \"Subject\":\"RepetitionDuration_Palm_gyr_rtVar\"]\n",
        "y = df[\"Borg\"]\n",
        "\n",
        "#Split the data 70/30, random_state is included for reproducibility\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.3, random_state=2)\n",
        "\n",
        "\n",
        "#KNN Regressor\n",
        "knn = neighbors.KNeighborsRegressor()\n",
        "\n",
        "#Fit the knn regressor to training data\n",
        "knn = knn.fit(X_train, y_train)\n",
        "\n",
        "#DT Regressor\n",
        "dtr = tree.DecisionTreeRegressor(random_state=2)\n",
        "\n",
        "#Fit the decision tree regressor to training data\n",
        "dtr = dtr.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "Zl0VXO0YH1nG"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Check the score of the regressor on test data\n",
        "knn.score(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKEyXvXTaYJJ",
        "outputId": "8cda1498-c347-4652-94da-1ae3ce4d2446"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3413960528822876"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Check the score of the regressor on test data\n",
        "dtr.score(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cfBcaynaW5A",
        "outputId": "ae04f373-10e7-46c3-f814-c5bd324587be"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3896182494349537"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The prediction score of the decision tree regressor was better than the KNN model. Decision tree (DT) has an accuracy of 0.39 and the KNN with 0.34, thus in this scenario, the DT performs slighty better.\n",
        "\n",
        "- Regarding execution times on the test, the DT also performs better when fitting and obtaining score to the test data. The DT executes in 0.009 seconds while the KNN fits in 0.255 seconds. This performance in DT can be attributed to the fact that ..."
      ],
      "metadata": {
        "id": "thR3efy-B2L-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Robust evaluation\n",
        "\n",
        "In this section, try to improve the accuracy by creating a pipeline. Consider the techniques we have covered during the semester, and try to improve the accuracy of a Decision tree regressor.\n",
        "Your report should provide concrete information of your reasoning; everything should be well-explained.\n",
        "Do not get stressed if the things you try do not improve the accuracy. The key to getting good marks is to show that you evaluated different methods and that you correctly selected the configuration.\n"
      ],
      "metadata": {
        "id": "zADpr0f8IcGL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "#Create pipeline\n",
        "regressorDT = Pipeline([\n",
        "        ('regressor', tree.DecisionTreeRegressor(random_state=2))])\n",
        "\n",
        "#Create parameter grid\n",
        "dt_param_grid = {\n",
        "    \"regressor__criterion\": [\"squared_error\", \"absolute_error\"],\n",
        "    'regressor__splitter': ['best', 'random'],\n",
        "    \"regressor__max_depth\": [None, 3, 5],\n",
        "    \"regressor__min_samples_split\": [2, 5]}\n",
        "\n",
        "#Initialize GridSearchCV\n",
        "dtr_gs = GridSearchCV(regressorDT, dt_param_grid, scoring=\"neg_mean_squared_error\")\n",
        "\n",
        "#Fit the GridSearchCV object to the training dataset\n",
        "dtr_gs.fit(X_train, y_train)\n",
        "\n",
        "#Upon fitting we can access the optimal parameters from the best model\n",
        "print(f\"Best gridsearch parameters: {dtr_gs.best_params_}, best MSE score {dtr_gs.best_score_}\")\n",
        "\n",
        "\n",
        "#Take the best hyperparameters from the GridSearch and use regressor pipeline\n",
        "regressorDT.set_params(**dtr_gs.best_params_)\n",
        "# Fit the pipeline with the training data using the best parameters found\n",
        "regressorDT.fit(X_train, y_train)\n",
        "\n",
        "#Observe training set accuracy\n",
        "print(f\"R squared score on train set: {regressorDT.score(X_train, y_train)}\")\n",
        "# Calculate the accuracy on the test set\n",
        "print(f\"R squared score on test set: {regressorDT.score(X_test, y_test)}\")"
      ],
      "metadata": {
        "id": "tvBZH6ilInsA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ec30dee-f1e9-4878-9d8e-732b70df95bf"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best gridsearch parameters: {'regressor__criterion': 'squared_error', 'regressor__max_depth': 5, 'regressor__min_samples_split': 5, 'regressor__splitter': 'random'}, best MSE score -4.777111684787462\n",
            "R squared score on train set: 0.6412712975765836\n",
            "R squared score on test set: 0.5697470166158647\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "\n",
        "# Create pipeline with SelectKBest for feature selection\n",
        "regressorDT = Pipeline([\n",
        "        ('dr', PCA(n_components = 100)),\n",
        "        ('regressor', tree.DecisionTreeRegressor(random_state=2))])  # Decision Tree Regressor\n",
        "\n",
        "# Create parameter grid for GridSearchCV\n",
        "dt_param_grid = {\n",
        "    \"regressor__criterion\": [\"squared_error\", \"absolute_error\"],\n",
        "    'regressor__splitter': ['best', 'random'],\n",
        "    \"regressor__max_depth\": [None, 3, 5],\n",
        "    \"regressor__min_samples_split\": [2, 5]}\n",
        "\n",
        "# Initialize GridSearchCV with 'neg_mean_squared_error' for regression task\n",
        "dtr_gs = GridSearchCV(regressorDT, dt_param_grid, scoring=\"neg_mean_squared_error\")\n",
        "\n",
        "# Fit the GridSearchCV object to the training dataset\n",
        "dtr_gs.fit(X_train, y_train)\n",
        "\n",
        "# Upon fitting, we can access the optimal parameters from the best model\n",
        "print(\"Best Parameters:\", dtr_gs.best_params_)\n",
        "print(\"Best Score (Negative MSE):\", dtr_gs.best_score_)\n",
        "\n",
        "# Take the best hyperparameters from the GridSearch and update the regressor pipeline\n",
        "regressorDT.set_params(**dtr_gs.best_params_)\n",
        "\n",
        "# Fit the pipeline with the training data using the best parameters found\n",
        "regressorDT.fit(X_train, y_train)\n",
        "\n",
        "#Observe training set accuracy\n",
        "print(f\"R squared score on train set: {regressorDT.score(X_train, y_train)}\")\n",
        "# Calculate the accuracy on the test set\n",
        "print(f\"R squared score on test set: {regressorDT.score(X_test, y_test)}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "znNNNQSyYHbd",
        "outputId": "c13a7446-8621-477f-f7b2-b0193cb6f9ca"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'regressor__criterion': 'squared_error', 'regressor__max_depth': 3, 'regressor__min_samples_split': 2, 'regressor__splitter': 'best'}\n",
            "Best Score (Negative MSE): -9.910632299032228\n",
            "R squared score on train set: 0.15030475240652186\n",
            "R squared score on test set: 0.0576822726773325\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import SelectKBest, f_regression\n",
        "\n",
        "# Create pipeline with SelectKBest for feature selection\n",
        "regressorDT = Pipeline([\n",
        "        ('fs', SelectKBest(f_regression, k=50)),\n",
        "        ('regressor', tree.DecisionTreeRegressor(random_state=2))])\n",
        "\n",
        "# Create parameter grid for GridSearchCV\n",
        "dt_param_grid = {\n",
        "    \"regressor__criterion\": [\"squared_error\", \"absolute_error\"],\n",
        "    'regressor__splitter': ['best', 'random'],\n",
        "    \"regressor__max_depth\": [None, 3, 5],\n",
        "    \"regressor__min_samples_split\": [2, 5]}\n",
        "\n",
        "# Initialize GridSearchCV with 'neg_mean_squared_error' for regression task\n",
        "dtr_gs = GridSearchCV(regressorDT, dt_param_grid, scoring=\"neg_mean_squared_error\")\n",
        "\n",
        "# Fit the GridSearchCV object to the training dataset\n",
        "dtr_gs.fit(X_train, y_train)\n",
        "\n",
        "# Upon fitting, we can access the optimal parameters from the best model\n",
        "print(\"Best Parameters:\", dtr_gs.best_params_)\n",
        "print(\"Best Score (Negative MSE):\", dtr_gs.best_score_)\n",
        "\n",
        "# Take the best hyperparameters from the GridSearch and update the regressor pipeline\n",
        "regressorDT.set_params(**dtr_gs.best_params_)\n",
        "\n",
        "# Fit the pipeline with the training data using the best parameters found\n",
        "regressorDT.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "#Observe training set accuracy\n",
        "print(f\"R squared score on train set: {regressorDT.score(X_train, y_train)}\")\n",
        "# Calculate the accuracy on the test set\n",
        "print(f\"R squared score on test set: {regressorDT.score(X_test, y_test)}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8CAVVjVOzcH",
        "outputId": "09e4b895-b830-41a8-d759-1375aa796623"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'regressor__criterion': 'squared_error', 'regressor__max_depth': 3, 'regressor__min_samples_split': 2, 'regressor__splitter': 'best'}\n",
            "Best Score (Negative MSE): -4.818710629412834\n",
            "R squared score on train set: 0.5807372072896635\n",
            "R squared score on test set: 0.5677301203289373\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will deploy a hyperparametrisation of the parameters in order to find the most optimal parameters for the model as opposed to leaving default ones as these will not be optimal for all tasks. The goal here is to find the best hyperparameters that will maximise the performance of the model on the particular dataset. Rather than tuning these hyperparameters by user-input which can result in overfitting due to over-tuning the parameters, coss-validation will be deployed particularly GridSearchCV to find the optimal hyperparameters for the model. It is crucial to create a parameter grid for GridSearchCV to access a variety of parameters to find the optimal hyperparameters for the model, however it should be noted that the grid should consist of a manageable amount of parameters to avoid increasing computational effort and overfitting. The default cv value of 3 is used, this means that the model will split the datset into five equal parts, where k-1 folds will be used for training and the final part for validation. This is repeated for every fold, thus five different test folds will be used for testing. Typically, a smaller k fold value is used for larger and high dimensional datasets, while larger folds are fold smaller datasets.\n",
        "\n",
        "Regarding the GridSearchCV, we also define how the to evaluate the model. In this case we select 'neg_mean_squared_error' to minimize the mean squared error. This will quantify the size of the error between predictions of the model and a real output by obtaining the mean of squared differences between true target values and the predictions of the model. Again this loss will attribute greater penalties for more significant differences. GridSearchCV enables an exhaustive search over a user specified range of parameter values grid search provided by GridSearchCV exhaustively generates searches a grid of parameter values that were specified in the code above with dt_param_grid will be used to generate candidates for GridSearchCV.\n",
        "\n",
        "The application of GridSearchCV will begin by specifying the parameter grid, followed by initialising the GridSearch object with specified scoring and pipeline object. Following this, we will fit the GridSearch to the training data and eventually fit the optimal parameters to the pipeline regressor and evaluate this model on the test set.\n",
        "\n",
        "---\n",
        "The following parameters were chosen and here is why. To begin criterion for measuring the quality of split is selected to decide what function to deploy upon calculating the quality. We have mean squared error which will emphasize more high errors and have less effect induces by smaller errors and the mean absolute error which will be robust to potential outliers and not set proportions of importance to errors of any errors. The aim of this is to reduce impurity, thus we ideally want the value of the MSE to be as close to 0 as possible for each split.\n",
        "\n",
        "Following criterion, we have splitter parameter which determines the strategy for splitting each node. \"best\" will determine split in a greedy fashion while \"random\" will do so randomly. This can aid in reduction of overfitting\n",
        "\n",
        "We will also include max_depth, which will determine the maximum depth of that the tree can reach. It is crucial to avoid setting this parameter to high, to avoid risk of overfitting however if set too low, the mode may not generalize well and pick up key patterns in the data.\n",
        "\n",
        "Finally the last parameter chosen, was min_samples split which determine the minimum amount of samples that is required to split an internal node. Essentially any node that has fewer samples than the specified amount, no split will occur. This will work alongside max_depth to control the depth of the tree and enable better generalisation performance of the model due to broader and meaningful splits. Generally speaking the parameters such as max_depth and and min_split will regularise the model and reduce risk of overfitting as the model is not left to train without any constraints.\n",
        "\n",
        "In this task, to possibly improve the accuracy of the DT regressor we can deploy dimensionality reduction, this will certainly reduce computational effort and training will be less time-consuming.\n",
        "\n",
        "---\n",
        "\n",
        "Additionally, the dataset consist of many features (583 rows, 2173 columns), thus the model may struggle to perform well in this high-dimensional data due to the high amount of features present in the data. One issue related to high-dimensional data refers curse of dimensionality where the effectiveness and efficiency of a model will degrade as the number of features grows. This issue can result in increased risk of overfitting, false correlations, irrelevant and redudant features, thus dimesionality reduction will be deployed to mitigate the issues described.\n",
        "\n",
        "Principal component analysis (PCA), is a feature extraction method that will be deployed in order to deal with these issues. PCA will reduce the number of features that preserve the information and also attempt to locate the most meaningful basis to re-express the dataset. Additionally, we hope to filter out any noise and redundancy with this new basis. The dimensionality of the dataset will reduce from 2713 dimensions to 300.\n",
        "\n",
        "The n component value for PCA should retain as much variance within the dataset as possible, additionally we ensure that the value chosen is not small to avoid oversimplifying the data resulting in the model posessing poor generalization ability and perform poorly.\n",
        "\n",
        "\n",
        "***TALK ABOUT PCA PERFORMANCE***\n",
        "\n",
        "---\n",
        "\n",
        "***FINISH OFF BY TALKING ABOUT FEATURE SELECTION AND WHY WE HAVE IT***\n",
        "\n",
        "- Regarding the high-dimensional data another approach dimensionality reduction approach we can take, is feature selection particularly, SelectKBest. This method will ...\n",
        "\n",
        "- While this may not improve the score of the model, it does greatly reduce the training time and also further reduce risk of overfitting as we control the amount of noise within the data with feature selection.\n",
        "---\n",
        "- **NOTE THE ACCRURACIES OF THE MODELS AND DERSCIBRE WHY IT IS EITHER BETTER OR WORSE ???**"
      ],
      "metadata": {
        "id": "SplMxwdqplsg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## New classifier\n",
        "\n",
        "Replicate the previous task for a classifier that we did not cover in class (different than K-NN and decision trees). Briefly describe and justify your choice.\n",
        "Try to create the best model for the given dataset.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FYoMg0EZIrNd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "\n",
        "\n",
        "#Create pipeline\n",
        "XGBoostR = Pipeline([\n",
        "        ('fs', SelectKBest(f_regression, k=50)),\n",
        "        ('xgb', GradientBoostingRegressor(random_state=2))])\n",
        "#Create parameter grid\n",
        "xgbr_param_grid = {'xgb__loss' : ['squared_error', 'absolute_error', 'huber'],\n",
        "                 'xgb__criterion' : ['friedman_mse', 'squared_error'],\n",
        "                 'xgb__learning_rate' : [0.01, 0.1, 0.2],\n",
        "                 'xgb__n_estimators' : [100, 250, 500],\n",
        "                 'xgb__max_depth': [None, 3, 5],\n",
        "                 'xgb__min_samples_split': [2, 5]}\n",
        "\n",
        "#Initialize GridSearchCV\n",
        "xgbr_gs = GridSearchCV(XGBoostR, xgbr_param_grid, scoring=\"neg_mean_squared_error\")\n",
        "\n",
        "#Fit the GridSearchCV object to the training dataset\n",
        "xgbr_gs.fit(X_train, y_train)\n",
        "\n",
        "#Upon fitting we can access the optimal parameters from the best model\n",
        "print(f\"Best gridsearch parameters: {xgbr_gs.best_params_}, best MSE score {xgbr_gs.best_score_}\")\n",
        "\n",
        "\n",
        "#Take the best hyperparameters from the GridSearch and use regressor pipeline\n",
        "XGBoostR.set_params(**xgbr_gs.best_params_)\n",
        "# Fit the pipeline with the training data using the best parameters found\n",
        "XGBoostR.fit(X_train, y_train)\n",
        "\n",
        "# Calculate the accuracy on the test set\n",
        "print(f\"R squared score on train set: {XGBoostR.score(X_train, y_train)}\")\n",
        "print(f\"R squared score on test set: {XGBoostR.score(X_test, y_test)}\")\n",
        "\n",
        "\n",
        "# - SVM ?\n",
        "# - RandomForestRegressor\n",
        "# - XGBoost Regressor"
      ],
      "metadata": {
        "id": "QRJXrY2hI32F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "\n",
        "\n",
        "#Create pipeline\n",
        "XGBoostR = Pipeline([\n",
        "        ('regressor', GradientBoostingRegressor(random_state=2))])\n",
        "#Create parameter grid\n",
        "xgb_param_grid = {'regressor__loss' : ['squared_error', 'absolute_error', 'huber'],\n",
        "                 'regressor__criterion' : ['friedman_mse', 'squared_error'],\n",
        "                 'regressor__learning_rate' : [0.0001, 0.001, 0.01, 0.1, 0.2],\n",
        "                 'regressor__n_estimators' : [100, 250, 500],\n",
        "                 'regressor__max_depth': [None, 3, 5],\n",
        "                 'regressor__min_samples_split': [2, 5]}\n",
        "\n",
        "#Initialize GridSearchCV\n",
        "xgbr_gs = GridSearchCV(regressorDT, dt_param_grid, scoring=\"neg_mean_squared_error\")\n",
        "\n",
        "#Fit the GridSearchCV object to the training dataset\n",
        "xgbr_gs.fit(X_train, y_train)\n",
        "\n",
        "#Upon fitting we can access the optimal parameters from the best model\n",
        "print(f\"Best gridsearch parameters: {xgbr_gs.best_params_}, best MSE score {xgbr_gs.best_score_}\")\n",
        "\n",
        "\n",
        "#Take the best hyperparameters from the GridSearch and use regressor pipeline\n",
        "XGBoostR.set_params(**xgbr_gs.best_params_)\n",
        "# Fit the pipeline with the training data using the best parameters found\n",
        "XGBoostR.fit(X_train, y_train)\n",
        "\n",
        "# Calculate the accuracy on the test set\n",
        "print(f\"R squared score on train set: {XGBoostR.score(X_train, y_train)}\")\n",
        "print(f\"R squared score on test set: {XGBoostR.score(X_test, y_test)}\")\n",
        "\n",
        "\n",
        "# - SVM ?\n",
        "# - RandomForestRegressor\n",
        "# - XGBoost Regressor"
      ],
      "metadata": {
        "id": "Ttu-UQNi-QlD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation on unseen instances (Only for CS6405)\n",
        "Save your best model into your github. And create a single code cell that loads it and evaluate it on the following test dataset:\n",
        "https://raw.githubusercontent.com/andvise/DM_Assignment_2425/refs/heads/main/test_data.csv\n",
        "\n",
        "This link currently contains a sample of the training set. The real test set will be released after the submission. I should be able to run the code cell independently and load all the libraries you need as well.\n",
        "\n"
      ],
      "metadata": {
        "id": "Q01BjiiCJTR4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from joblib import dump, load\n",
        "from io import BytesIO\n",
        "import requests\n",
        "import pandas as pd\n",
        "\n",
        "# INSERT YOUR MODEL'S URL\n",
        "mLink = 'https://github.com/andvise/my_model/raw/refs/heads/main/model.joblib'\n",
        "mfile = BytesIO(requests.get(mLink).content)\n",
        "model = load(mfile)\n",
        "\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/andvise/DM_Assignment_2425/refs/heads/main/test_data.csv\")\n"
      ],
      "metadata": {
        "id": "IWx4lyuQI929"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "9Lx5OKyU-LnW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}