{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ErenB02/comp_bio/blob/main/EXAMNOTES.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Pre-processing**"
      ],
      "metadata": {
        "id": "tbXthBaKXpBq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Convert cat to num* (no label enc)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "LeembPz4XXco"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['work_type'].replace(['Private', 'Self-employed','Govt_job','children'], [0,2,1,3], inplace = True)\n",
        "df['ever_married'].replace(['Yes', 'No'], [0,1], inplace = True)"
      ],
      "metadata": {
        "id": "-05e-HKDXWfx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Deleting cols*"
      ],
      "metadata": {
        "id": "heKd9XV1XsJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Avoid bias\n",
        "#Data specific (dependon on what we want to look for)\n",
        "del df['colname']"
      ],
      "metadata": {
        "id": "q3iocJ5SXuBZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Target and features Selection*"
      ],
      "metadata": {
        "id": "5ba--w2_ZXcN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = df['house_price_per_unit']\n",
        "\n",
        "#loc syntax = [row selection, column selection]\n",
        "#We use : in row to get all rows\n",
        "#We use : again but stop at longitude\n",
        "X = df.loc[:, :\"longitude\"]"
      ],
      "metadata": {
        "id": "uwyzHIHoZa88"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Min Max Scaler*"
      ],
      "metadata": {
        "id": "JFVck2KFX47R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "scaler.fit(X_train)\n",
        "## Equivalent to\n",
        "# min_train = X_train.min()\n",
        "# max_train = X_train.max()\n",
        "\n",
        "X_train = scaler.transform(X_train)\n",
        "## Equivalent to\n",
        "# X_train = (X_train - min_train)/ (max_train - min_train)\n",
        "\n",
        "X_test = scaler.transform(X_test)\n",
        "## Equivalent to\n",
        "# X_test = (X_test - min_train)/ (max_train - min_train)\n",
        "\n",
        "#Stored original data\n",
        "print(scaler.data_min_)\n",
        "print(scaler.data_max_)\n",
        "\n",
        "#Fit the scaler on the training data to learn the scaling parameters.\n",
        "#Transform both training and test data using the same scaling parameters (from the training set).\n",
        "#This ensures that the model is trained and evaluated on properly scaled data without any leakage from the test set"
      ],
      "metadata": {
        "id": "Pxc_xJppX7VP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Train-Test Split*\n"
      ],
      "metadata": {
        "id": "Sr47S4WKYx_r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "vGeLvr_lZf_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Label Encoder*"
      ],
      "metadata": {
        "id": "fP54abZgba2I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label = LabelEncoder()\n",
        "df[60] = label.fit_transform(df[60])\n"
      ],
      "metadata": {
        "id": "uhIv_OkQbcqz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **K-NN**\n"
      ],
      "metadata": {
        "id": "fKegHcCiA8Ic"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*KNN-Regressor*"
      ],
      "metadata": {
        "id": "2mSVbdqqZnrk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn import neighbors\n",
        "from sklearn import metrics\n",
        "from sklearn import model_selection\n",
        "import matplotlib.pyplot as plt\n",
        "#VERY IMPORTANT POINT HERE\n",
        "#kNN Regressor is used for regression tasks, where the goal is to predict a continuous output value (e.g., predicting house prices, sales, etc.)\n",
        "knn = neighbors.KNeighborsRegressor()\n",
        "parameters = {'n_neighbors': [1, 3, 5, 7, 9], 'p': [1, 2]}\n",
        "\n",
        "# Initialize the GridSearchCV object\n",
        "# GridSearchCV will try all combinations of the given hyperparameters\n",
        "# 'scoring' defines how to evaluate the model, we use 'neg_mean_squared_error' to minimize the MSE\n",
        "clf = model_selection.GridSearchCV(knn, parameters, scoring='neg_mean_squared_error')\n",
        "clf.fit(X_train, y_train)\n",
        "# Use case: MAE measures the average magnitude of the errors in a set of predictions, without considering their direction (positive or negative).\n",
        "#It is easier to interpret than MSE since it gives the average absolute difference between predicted and actual values.\n",
        "# When to use: MAE is better when you care more about the absolute error, and you don't want to penalize large errors as severely as MSE.\n",
        "#It's useful if you need a more robust metric against outliers, as large errors don't get squared.\n",
        "\n",
        "# After fitting, you can access the best model and the corresponding parameters\n",
        "clf.best_estimator_.score(X_test, y_test)\n",
        "\n",
        "\n",
        "\n",
        "#Using negative MSE\n",
        "#Thus we look for the best maximizing score\n",
        "# -75 since we have negative MSE\n",
        "clf.best_score_\n",
        "\n",
        "\n",
        "#PRINT BEST PARAMS\n",
        "#Retrieves the best parameters from GridSearchCV\n",
        "clf.best_params_\n",
        "\n",
        "\n",
        "#EVALUATE THE BEST MODEL ON TEST SET\n",
        "#clf.best_estimator_: The best model found after GridSearchCV.\n",
        "#.score(X_test, y_test): Evaluates the best model on the test set\n",
        "clf.best_estimator_.score(X_test, y_test)\n"
      ],
      "metadata": {
        "id": "dbInjkj2A91o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Decision Tree**"
      ],
      "metadata": {
        "id": "k0blLpunBL4N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Parameters*"
      ],
      "metadata": {
        "id": "WmLT8M1dDVMg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# - criterion\n",
        "#     - determines function used to measure the quality of a split in the DT\n",
        "      #  (e.g “gini” measures impurity split by calculating probability of a randomly chosen element being missclassified)(e.g entropy…)\n",
        "\n",
        "# - splitter\n",
        "#     - defines splitting strategy (e.g “best”, “random” → can reduce overfitting)\n",
        "\n",
        "# - max_depth\n",
        "#     - controls maximum depth of tree (e.g None, Limiting depth can also help prevent overfitting)\n",
        "\n",
        "# - min_samples_split\n",
        "#     - This specifies the minimum number of samples that a leaf node must have.\n",
        "\n",
        "# - min_samples_leaf\n",
        "#     - This parameter defines the minimum number of samples required to split an internal node.\n",
        "      # If a node has fewer than this number of samples, it will not be split.\n",
        "\n",
        "# - min_weight_fraction_leaf\n",
        "#     - This parameter is similar to `min_samples_leaf`, but instead of a number of samples,\n",
        "    # it specifies the minimum weighted fraction of the total sample weight required to be at a leaf node. (good for weighted data)\n",
        "\n",
        "dt_param_grid = {\n",
        "    \"classifier__criterion\": [\"gini\", \"entropy\"],  # Function for split quality\n",
        "    \"classifier__splitter\": [\"best\", \"random\"],  # Split strategy\n",
        "    \"classifier__max_depth\": [None, 3, 5, 10, 15],  # Tree depth control\n",
        "    \"classifier__min_samples_split\": [2, 5, 10],  # Minimum samples to split\n",
        "    \"classifier__min_samples_leaf\": [1, 2, 4, 10],  # Minimum samples per leaf\n",
        "    \"classifier__min_weight_fraction_leaf\": [0.0, 0.1, 0.2],  # Weighted fraction for leaf nodes\n",
        "    \"classifier__ccp_alpha\": [0.0, 0.01, 0.1, 1.0]  # Pruning parameter\n",
        "}\n",
        "\n"
      ],
      "metadata": {
        "id": "GHruMiEXBPll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*DT Fit*"
      ],
      "metadata": {
        "id": "0BpbKtbaDb6R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import model_selection\n",
        "\n",
        "#Applies split\n",
        "train_features, test_features, train_labels, test_labels\n",
        "= model_selection.train_test_split(features, labels,\n",
        "test_size=0.2, random_state=0)\n",
        "\n",
        "\n",
        "#Fits to training data\n",
        "dtc = dtc.fit(train_features, train_labels)\n",
        "\n",
        "#Checks score on test data (final evaluation of model)\n",
        "dtc.score(test_features, test_labels)\n",
        "\n",
        "#DONT WANT TO NORMALIZE, WORK ON SPLITTING FEATURE VALUES\n",
        "#THESE FEATURES DO NOT DEPEND ON THE SCALE OF FEATURES"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "4nfcQV-oDZS0",
        "outputId": "87415c9f-6ff9-4dda-84a4-d55afadbbb39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-2-5606aa050648>, line 5)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-5606aa050648>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    = model_selection.train_test_split(features, labels,\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Plot Tree*"
      ],
      "metadata": {
        "id": "couVf7yvDqWv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(30, 30)) # Resize figure\n",
        "tree.plot_tree(dtc)"
      ],
      "metadata": {
        "id": "CbkGPGWmDsnO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Entropy*"
      ],
      "metadata": {
        "id": "MCfIRRrfD3PK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dtc = tree.DecisionTreeClassifier(criterion = \"entropy\",\n",
        "max_depth= 2, min_samples_split = 5)"
      ],
      "metadata": {
        "id": "K3vTawpQD4f4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Baseline Accuracy**"
      ],
      "metadata": {
        "id": "KRpP0_2HBmVc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Find most common class\n",
        "y_train.mode()\n",
        "\n",
        "#Compute how often this class appears in the test set\n",
        "(y_test ==y_train.mode()[0]).mean()\n",
        "\n",
        "\n",
        "y_train.mode() # the most common class is ...\n",
        "\n",
        "(y_test == 0).mean()"
      ],
      "metadata": {
        "id": "yjlN5ywzBo3Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Confusion Matrix**"
      ],
      "metadata": {
        "id": "JMZNyIETCbQm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import neighbors\n",
        "from sklearn import metrics\n",
        "from sklearn import model_selection\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "cm = metrics.confusion_matrix(test_labels, predictions, labels = knn.classes_)\n",
        "\n",
        "disp = metrics.ConfusionMatrixDisplay(confusion_matrix=cm,\n",
        "display_labels=knn.classes_)\n",
        "disp.plot()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "iXnD6D17Cd9G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cross Validation**"
      ],
      "metadata": {
        "id": "y5cb-y_yCuDm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scores = model_selection.cross_val_score(knn, train_features, train_labels, cv=10)\n",
        "print(scores)\n",
        "\n",
        "# The purpose of cross-validation:\n",
        "# - It gives an estimate of model performance on different subsets of the training data.\n",
        "# - If accuracy varies a lot across folds, the model may be unstable (high variance).\n",
        "# - If accuracy is consistently low, the model might be underfitting.\n",
        "# - We can use these insights to decide if we need to tune hyperparameters (e.g., try different K values).\n"
      ],
      "metadata": {
        "id": "O7ZAlBfTCvdx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GridSearchCV**"
      ],
      "metadata": {
        "id": "C5gRYzqvC2jn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Creates GS, stores KNN model, stores parameters, prepares cross val, no training yet\n",
        "clf = model_selection.GridSearchCV(knn, parameters)\n",
        "\n",
        "#Runs cross val, trains knn using every parameter, evaluates model, selects best one\n",
        "#Stores best model, best acc and best param\n",
        "clf.fit( train_features, train_labels)\n",
        "print(\"The best classifier is:\", clf.best_estimator_)\n",
        "print(\"Its accuracy is:\",clf.best_score_)\n",
        "print(\"Its parameters are:\",clf.best_params_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "OkI1BqLmC2op",
        "outputId": "d01d9a9a-2a74-4457-b98d-25ef6959e235"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model_selection' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-4c4d0331401f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Creates GS, stores KNN model, stores parameters, prepares cross val, no training yet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_selection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mknn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#Runs cross val, trains knn using every parameter, evaluates model, selects best one\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#Stores best model, best acc and best param\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model_selection' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MinMaxScaler**"
      ],
      "metadata": {
        "id": "WklRvPLhC-yK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Fit both sets using the same scaler (FIT IS DONE HERE)\n",
        "train_features = scaler.transform(train_features)\n",
        "test_features = scaler.transform(test_features)\n",
        "\n",
        "knn.fit(train_features, train_labels)\n",
        "\n",
        "# Predict the classes\n",
        "results = knn.predict(test_features)\n",
        "# Compute the accuracy\n",
        "print(metrics.accuracy_score(results, test_labels))\n",
        "\n",
        "\n",
        "#Prints stored min and max values from pre-scaled dataset\n",
        "print(sorted(scaler.data_min_))\n",
        "print(sorted(scaler.data_max_))"
      ],
      "metadata": {
        "id": "TDaZ7isGDAxB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hyperparameters**"
      ],
      "metadata": {
        "id": "FVaIBGqnD87D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import tree\n",
        "from sklearn import model_selection\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "dtc = tree.DecisionTreeClassifier()\n",
        "\n",
        "#Criterion descides if we split based on gini or entropy\n",
        "#Max-depth & min_impurity_decrease for split to occur\n",
        "parameters = {'criterion': [\"entropy\", \"gini\"], 'max_depth' : [2,\n",
        "3, 4], 'min_impurity_decrease' : [0.01, 0.1, 0.2] }\n",
        "\n",
        "train_features, test_features, train_labels, test_labels =\n",
        "model_selection.train_test_split(features, labels, test_size=0.2,\n",
        "random_state=0)\n",
        "\n",
        "#Exhaustive search over all hyperparameter combinations using 10-fold\n",
        "clf = model_selection.GridSearchCV(dtc, parameters, cv = 10)\n",
        "#Trains models with different hyperparameter settings & selects best one\n",
        "clf.fit(train_features, train_labels)\n",
        "\n",
        "print(\"The best classifier is:\", clf.best_estimator_)\n",
        "print(\"Its accuracy is:\",clf.best_score_)\n",
        "print(\"Its parameters are:\",clf.best_params_)\n",
        "\n",
        "# The performances on the test set are:\n",
        "clf.best_estimator_.score(test_features, test_labels)"
      ],
      "metadata": {
        "id": "1J2Dbx9qD-I_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Category Mapping**"
      ],
      "metadata": {
        "id": "Tp_tYGxBJwPj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_le = LabelEncoder()\n",
        "#Assumes ordering\n",
        "df['Feature'] = class_le.fit_transform(df['Feature'].values)"
      ],
      "metadata": {
        "id": "whjZLUIvEBj1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**One Hot encoding**"
      ],
      "metadata": {
        "id": "TiLxrJlBKIjd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TYPICALLY APPLY DIMENSIONALITY REDUCTION IN THIS CASE\n",
        "df = pd.get_dummies(df, columns=[\"Department\"])\n",
        "print(df)\n",
        "\n",
        "# - **Hamming Distance** → Best for **pure categorical** comparisons.\n",
        "# - **Manhattan Distance** → Works well for **high-dimensional, sparse OHE data**.\n",
        "# - **Euclidean Distance** → Less ideal for OHE, but useful if combining OHE with numerical features."
      ],
      "metadata": {
        "id": "GBoLKJjuKKkV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Bag Of Words**"
      ],
      "metadata": {
        "id": "G0PjFwOBKfzy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Pre-processing*"
      ],
      "metadata": {
        "id": "TVcVJn_WcTHE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "y = df['Sentiment']\n",
        "\n",
        "X = df['Review']\n",
        "\n",
        "encoder = LabelEncoder()\n",
        "\n",
        "y = encoder.fit_transform(y)\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)"
      ],
      "metadata": {
        "id": "U62AZemLKi_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Classification Task*"
      ],
      "metadata": {
        "id": "0Hw7sgZecXpm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from sklearn import neighbors\n",
        "from sklearn import metrics\n",
        "from sklearn import model_selection\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Initialize the CountVectorizer (for Bag of Words model)\n",
        "vec = CountVectorizer()\n",
        "\n",
        "# Initialize TruncatedSVD for dimensionality reduction (similar to PCA)\n",
        "svd = TruncatedSVD(n_components=50)\n",
        "\n",
        "\n",
        "#NUM TO WORDS (Count Verctorizer)\n",
        "# Apply Bag of Words model on training data\n",
        "X_train = vec.fit_transform(X_train)  # Convert text data to a sparse matrix of word counts\n",
        "\n",
        "#DIMENSIONALITY REDUCTION\n",
        "# Apply TruncatedSVD to reduce dimensionality of the feature space\n",
        "X_train = svd.fit_transform(X_train)  # Reduce features while retaining 50 components\n",
        "\n",
        "\n",
        "# Initialize KNN classifier\n",
        "knn = neighbors.KNeighborsClassifier()\n",
        "\n",
        "# Define the grid of hyperparameters to search over\n",
        "parameters = {'n_neighbors': [1, 3, 5],  # Number of neighbors to use\n",
        "              'p': [1,2]}  # Distance metric to use (1 = Manhattan, 2 = Euclidean)\n",
        "\n",
        "# Initialize GridSearchCV to search for the best hyperparameters\n",
        "clf = model_selection.GridSearchCV(knn, parameters)\n",
        "\n",
        "# Fit the grid search with training data\n",
        "clf.fit(X_train, y_train)  # Perform cross-validation to find the best hyperparameters\n",
        "\n",
        "# Print the best classifier found by the grid search\n",
        "print(\"The best classifier is:\", clf.best_estimator_)\n",
        "# Print the best accuracy score from cross-validation\n",
        "print(\"Its accuracy is:\", clf.best_score_)\n",
        "# Print the best hyperparameters found during grid search\n",
        "print(\"Its parameters are:\", clf.best_params_)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Preprocess the test data using the same vectorizer and SVD\n",
        "X_test = vec.transform(X_test)  # Convert test text data to the same sparse matrix form\n",
        "X_test = svd.transform(X_test)  # Apply the same dimensionality reduction to the test data\n",
        "\n",
        "# Evaluate the best model from grid search on the test set\n",
        "clf.best_estimator_.score(X_test, y_test)  # Compute the accuracy of the best model on test data\n",
        "\n",
        "\n",
        "# clf.best_estimator_ gives you the best model found by grid search.\n",
        "# clf.best_estimator_.score() gives you the performance of that model on test data"
      ],
      "metadata": {
        "id": "udEHZ2SVcaT3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Data Reduction/Dimensionality Redcution**"
      ],
      "metadata": {
        "id": "WaovhWw0LWq0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Most of the techniues may not be effective for high-dimensional data\n",
        "\n",
        "# - What is the curse of dimensionality ?\n",
        "#     - Arises when working with high-dimensional data →\n",
        "#       leading to increased computational complexity, risk of overfitting and spurious correlations\n",
        "\n",
        "#     - Curse of Dimensionality refers to the phenomenon where the efficiency and effectiveness of algorithms deteriorate\n",
        "#       as the dimensionality of the data increases exponentially.\n",
        "\n",
        "# - Is there always a need for DR and if so, when and why ?\n",
        "#     - Especially when dealing large number of variables there is a need for DR\n",
        "#     - DR → CAN SIGNIFICANTLY IMPROVE LEARNING ALGORITHMS PERFORMANCE\n",
        "\n",
        "\n",
        "#BENEFITS\n",
        "\n",
        "# - Visualization → projection of high-dimensional data onto 2D or 3D\n",
        "# - Data compression → efficient storage and retrieval\n",
        "# - Noise removal → positive effect on query accuracy\n",
        "\n",
        "# Classifier performance degrades for a large number of features.\n",
        "# After a certain point increasing the dimensiaonlity of the problem by\n",
        "# adding new features would actually degrade the performance of the classifier."
      ],
      "metadata": {
        "id": "BbIBRwBnLa6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Feature Extraction**"
      ],
      "metadata": {
        "id": "nALvEMtZM1eN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Principal Component Analysis*\n",
        "\n"
      ],
      "metadata": {
        "id": "qCRbR2E_Nov5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from sklearn import neighbors  # K-Nearest Neighbors classifier\n",
        "from sklearn import metrics  # For model evaluation metrics\n",
        "from sklearn import model_selection  # For train-test split and hyperparameter tuning\n",
        "from sklearn.preprocessing import MinMaxScaler  # For feature scaling\n",
        "from sklearn.decomposition import PCA  # Principal Component Analysis (PCA)\n",
        "from sklearn.datasets import load_breast_cancer  # Load the breast cancer dataset\n",
        "\n",
        "# Load the breast cancer dataset\n",
        "data = load_breast_cancer()\n",
        "\n",
        "# Split data into training and testing sets (80% training, 20% testing)\n",
        "train_features, test_features, train_labels, test_labels = model_selection.train_test_split(\n",
        "    data.data,  # Feature matrix\n",
        "    data.target,  # Target variable (0 = malignant, 1 = benign)\n",
        "    test_size=0.2,  # 20% of data used for testing\n",
        "    random_state=10  # Ensures reproducibility of the split\n",
        ")\n",
        "\n",
        "# Scale features to the range [0,1] to improve PCA and KNN performance\n",
        "scaler = MinMaxScaler()\n",
        "train_features = scaler.fit_transform(train_features)  # Fit on training data and transform it\n",
        "test_features = scaler.transform(test_features)  # Transform test data using the same scaler\n",
        "\n",
        "# Apply Principal Component Analysis (PCA) to reduce dimensionality to 4 components\n",
        "pca = PCA(n_components=4)\n",
        "train_features = pca.fit_transform(train_features)  # Fit PCA on training data and transform it\n",
        "test_features = pca.transform(test_features)  # Transform test data with the trained PCA\n",
        "\n",
        "# Print the shape of the transformed training set (should be [n_samples, 4])\n",
        "print(\"Training set size \", train_features.shape)\n",
        "\n",
        "# Initialize a K-Nearest Neighbors classifier\n",
        "knn = neighbors.KNeighborsClassifier()\n",
        "\n",
        "# Define a dictionary of hyperparameters to tune (number of neighbors)\n",
        "parameters = {'n_neighbors': [1, 3, 5, 7, 11]}\n",
        "\n",
        "# Perform hyperparameter tuning using GridSearchCV\n",
        "clf = model_selection.GridSearchCV(knn, parameters)  # Grid search over K values\n",
        "clf.fit(train_features, train_labels)  # Train using cross-validation on training data\n",
        "\n",
        "# Print the best classifier and its performance\n",
        "print(\"The best classifier is:\", clf.best_estimator_)  # Best KNN model found\n",
        "print(\"Its accuracy is:\", clf.best_score_)  # Accuracy of best model on validation sets\n",
        "print(\"Its parameters are:\", clf.best_params_)  # Best hyperparameter (number of neighbors)"
      ],
      "metadata": {
        "id": "MPR4G1saNzcF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Truncated SVD*"
      ],
      "metadata": {
        "id": "2pqlNhzCN8F-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#WORKS BETTER FOR SPARSE DATASETS\n",
        "\n",
        "df = ...\n",
        "sparsity = 1.0 - (df != 0).mean().mean()\n"
      ],
      "metadata": {
        "id": "MMagx60RN-ox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Feature Selection**"
      ],
      "metadata": {
        "id": "A1ao-KOING5Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.2, random_state=42)\n",
        "\n",
        "# Select the top 10 features based on their statistical importance\n",
        "selector = SelectKBest(score_func=f_classif, k=10)\n",
        "X_train_selected = selector.fit_transform(X_train, y_train)\n",
        "X_test_selected = selector.transform(X_test)\n",
        "\n",
        "print(\"Original shape:\", X_train.shape)\n",
        "print(\"New shape after feature selection:\", X_train_selected.shape)\n",
        "\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Train a RandomForest model\n",
        "clf = RandomForestClassifier(random_state=42)\n",
        "clf.fit(X, y)\n",
        "\n",
        "# Get feature importances\n",
        "importances = pd.DataFrame({'Feature': data.feature_names, 'Importance': clf.feature_importances_})\n",
        "importances = importances.sort_values(by='Importance', ascending=True)  # Weakest first\n",
        "\n",
        "print(importances.head(10))  # Show weakest 10 features"
      ],
      "metadata": {
        "id": "0dJx2V6UNy5w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Pipeline**"
      ],
      "metadata": {
        "id": "KBm6p80rLcK0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Intermediate steps; sikit-learn transformer and last is the estimator\n",
        "  - MinMaxScaler, PCA and finally KNNClassifier"
      ],
      "metadata": {
        "id": "p0d78ZXSVH4u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#####################################################################################\n",
        "\n",
        "# Create a pipeline that sequentially applies transformations and classification\n",
        "pipe_lr = Pipeline([\n",
        "    ('scl', MinMaxScaler()),  # Step 1: Normalize features to range [0,1]\n",
        "    ('dr', PCA(8)),           # Step 2: Reduce dimensionality to 8 principal components\n",
        "    ('clf', neighbors.KNeighborsClassifier(5))  # Step 3: Apply K-Nearest Neighbors classifier with k=5\n",
        "])\n",
        "\n",
        "# Fit the pipeline on the training data\n",
        "pipe_lr.fit(train_features, train_labels)\n",
        "\n",
        "# Predict labels for the test set\n",
        "predictedResults = pipe_lr.predict(test_features)  # Here, test_features undergo the same transformations as train_features\n",
        "\n",
        "# Compute and print accuracy\n",
        "print(metrics.accuracy_score(predictedResults, test_labels))\n",
        "\n",
        "# Alternatively, use the built-in pipeline `score` method, which computes accuracy directly\n",
        "print('Test Accuracy:', pipe_lr.score(test_features, test_labels))\n",
        "\n",
        "#########################################################################################\n",
        "\n",
        "##Cross validation of 10-fold (fit training on 9-folds and test on 1 fold) repeated 10 separate times\n",
        "##Pipeline followed before\n",
        "results = cross_val_score(pipe_lr, data.data, data.target,\n",
        "cv=10)\n",
        "\n",
        "print(results.mean())"
      ],
      "metadata": {
        "id": "3qhWIwCVLcaN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Hyperparametrization**"
      ],
      "metadata": {
        "id": "St871VI9Lcgg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Grid search*"
      ],
      "metadata": {
        "id": "Wdoa1gQ0ZRLH"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M6KXwJlzLhj5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Binary Classification**"
      ],
      "metadata": {
        "id": "AsaGKFQ_bvAb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Train-Test Split*"
      ],
      "metadata": {
        "id": "2qpt62SLbz4h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df.drop(60, axis=1)\n",
        "y = df[60]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42, stratify = y)\n",
        "\n",
        "print(\"Train set dimensions: \", X_train.shape, y_train.shape)\n",
        "print(\"Test set dimensions: \", X_test.shape, y_test.shape)"
      ],
      "metadata": {
        "id": "NMP2a9gBb3JB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Decision Tree Classifier*"
      ],
      "metadata": {
        "id": "j0uvEy8xb4df"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the DecisionTreeClassifier from sklearn\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "#NEVER FORGET TO INCLUDE RANOM STATE IN PIPELINES TOO FOR MARKING\n",
        "# Create an instance of the DecisionTreeClassifier with a fixed random state (for reproducibility)\n",
        "tree_classifier = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Train the decision tree model using the training data (X_train, y_train)\n",
        "tree_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test data (X_test) using the trained decision tree model\n",
        "prediction = tree_classifier.predict(X_test)\n",
        "\n",
        "# Print the accuracy of the predictions compared to the true labels (y_test)\n",
        "print(accuracy_score(y_test, prediction))"
      ],
      "metadata": {
        "id": "7OwwSCrPb77v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*GridSearch*"
      ],
      "metadata": {
        "id": "uXWLrgD6b9Z_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "parameter_grid = {\n",
        "    'criterion': ['gini', 'entropy', 'log_loss'],\n",
        "    'splitter': ['best', 'random'],\n",
        "    'min_samples_split': [2, 3, 4],\n",
        "    'min_samples_leaf' : [1, 2, 3, 4],\n",
        "    'max_depth': [1, 2],\n",
        "    'max_features': [1, 2]\n",
        "}\n",
        "\n",
        "#Grid search objects/parameters created and stored (5k folds)\n",
        "grid_search = GridSearchCV(DecisionTreeClassifier(), parameter_grid, cv = 5)\n",
        "\n",
        "# Fit the grid search on the training data to find the best hyperparameters\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data using the best model found from the grid search\n",
        "prediction = grid_search.predict(X_test)\n",
        "\n",
        "# Print the accuracy of the predictions from the grid search\n",
        "print(accuracy_score(y_test, prediction))"
      ],
      "metadata": {
        "id": "OkW47SJ-b_Tw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Support Vector Classifier*"
      ],
      "metadata": {
        "id": "FlAK4v7fcBk9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Importing the SVC (Support Vector Classifier) from sklearn\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# Create an instance of the SVM classifier with a fixed random state\n",
        "SVC_classifier = SVC(random_state=42)\n",
        "\n",
        "# Train the SVM classifier on the training data (X_train, y_train)\n",
        "SVC_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data using the trained SVM classifier\n",
        "prediction = SVC_classifier.predict(X_test)\n",
        "\n",
        "# Print the accuracy of the SVM model's predictions compared to the true labels\n",
        "print(accuracy_score(y_test, prediction))\n",
        "\n",
        "\n",
        "############################################################################\n",
        "\n",
        "\n",
        "\n",
        "# Decision Tree Classifier - May perform poorly due to overfitting, especially on high-dimensional data like Sonar\n",
        "\n",
        "\n",
        "# Hyperparameter tuning for Decision Trees is essential to avoid overfitting and improve performance\n",
        "\n",
        "#The chosen parameter grid might not be ideal for the data.\n",
        "#Decision trees can easily overfit, especially if the hyperparameters (like max_depth) aren't tuned properly.\n",
        "#The dataset itself might be challenging for a decision tree.\n",
        "\n",
        "\n",
        "\n",
        "# SVM performed better on the Sonar dataset:\n",
        "# - SVM can handle high-dimensional, non-linearly separable data better than Decision Trees.\n",
        "# - SVM uses kernels (like RBF) to map data to higher dimensions and find non-linear boundaries, while Decision Trees may overfit high-dimensional data.\n",
        "\n",
        "# Adjusting hyperparameters and experimenting with different classifiers (like SVM) can improve model performance.\n",
        "\n"
      ],
      "metadata": {
        "id": "oBIOne4McD2W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Micellaneous**"
      ],
      "metadata": {
        "id": "Ukvh5_G5YF3u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Distance Metrics*"
      ],
      "metadata": {
        "id": "vbP85bgjYWP0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Scales it using the scalers created above.\n",
        "#Finds the row with the minimum absolute distance (Manhattan) in the original DataFrame.\n",
        "\n",
        "def k_near_neigh(df, p):\n",
        "  diff = df - p\n",
        "  dist = diff.sum(axis = 1)\n",
        "  return dist.idxmin()\n",
        "\n",
        "\n",
        "r = [0.0, 0.816, 0.0, 1.0, 0.0, 0.0, 0.0, 0.8012, 0.6475, 0.000, 1.0]\n",
        "print(k_near_neigh(df, r))\n",
        "print(df.iloc[2784])"
      ],
      "metadata": {
        "id": "0EwGEzW_YKOQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Entropy*"
      ],
      "metadata": {
        "id": "g5_NblAtYYf1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import math\n",
        "def entropy(data, column):\n",
        "  ent = 0\n",
        "  # Loop through each unique category in the column\n",
        "  for c in data[column].unique():\n",
        "  # Calculate the probability of category 'c' in the column\n",
        "  # Anytime c(True) add to sum\n",
        "    p = sum(data[column] == c)/len(data)\n",
        "    ent -= p * math.log2(p)\n",
        "  # Complete the function\n",
        "  return ent\n",
        "\n",
        "print(sum(df[\"Survived\"] == 0))\n",
        "total = (sum(df[\"Survived\"] == 0)/ df.shape[0])*100\n",
        "print(total)\n",
        "\n",
        "\n",
        "#Very high value close to 1 as we have almost an equal amount of survived and not survived, thus making entropy almost totally random\n",
        "\n",
        "entropy(df, \"Survived\") # it should be 0.9618806789594468\n",
        "#####################################################################################################################################\n",
        "\n",
        "\n",
        "df_male = df[df[\"Sex\"] == \"male\"]#Filter df to contain males only in Sex column\n",
        "\n",
        "entropy(df_male, \"Survived\") # it should be 0.7019458258949879\n"
      ],
      "metadata": {
        "id": "-CZQQgwxYZnJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Information Gain*"
      ],
      "metadata": {
        "id": "J4TWYBa9YobR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def information_gain(data, target, branch):\n",
        "  ig = entropy(data, target)  # Step 1: Calculate the entropy of the target variable before the split (overall entropy)\n",
        "\n",
        "  for v in data[branch].unique():  # Step 2: Loop through each unique value of the branch column (in this case, \"Sex\")\n",
        "    data_v = data[data[branch] == v]  # Step 3: Subset the data for that value of the branch column (e.g., males or females)\n",
        "    ig -= len(data_v) / len(data) * entropy(data_v, target)  # Step 4: Subtract the weighted entropy for that subset (male or female)\n",
        "\n",
        "  return ig  # Step 5: Return the final Information Gain\n",
        "\n",
        "\n",
        "information_gain(df, 'Survived', 'Pclass')\n",
        "\n",
        "information_gain(df, 'Survived', 'Sex')\n",
        "\n",
        "\n",
        "\n",
        "#We can conclude that Sex is a stronger predictor of survival than Class, this is reflected in the information gain values,\n",
        "#where it can be observed that Pclass has a much lower value thus implying a lower reduction in entropy\n",
        "#and a lower reduction in entropy desrcribes a lower reduction in uncertainty and thus the node in this case should be Sex over Pclass"
      ],
      "metadata": {
        "id": "f5ToNY_xYpfj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Splitting on binary classification*"
      ],
      "metadata": {
        "id": "oYQQmD2mbl64"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop(60, axis=1)\n",
        "y = df[60]"
      ],
      "metadata": {
        "id": "ZOaYuUNRbo1C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **LAST LAB**"
      ],
      "metadata": {
        "id": "fOpctwT4cyjD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Preprocessing*"
      ],
      "metadata": {
        "id": "h5wigheLc8ME"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Encode categorical labels as numerical values\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder.fit(df['Sentiment'])\n",
        "df['Sentiment'] = label_encoder.transform(df['Sentiment'])"
      ],
      "metadata": {
        "id": "OR_0w75fc26e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#Perform 80/20 split on X = [\"features\"], y = [\"Sentiment\"], stratify=y can be added if slight imbalance is present\n",
        "#However, target is evenly split so stratify isnt really nessecary\n",
        "train_X, test_X, train_y, test_y = train_test_split(df['Review'], df['Sentiment'], train_size=0.8, random_state=2)"
      ],
      "metadata": {
        "id": "KjCqlpRGc_RX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Count Vectorizer & KNN Classifier**"
      ],
      "metadata": {
        "id": "T-rk1TV8dBBm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#IMPORTS FOR Pipeline CV, kNNClassifier, Cross_val score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import cross_val_score"
      ],
      "metadata": {
        "id": "63OHlQ1RdD2O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "classifier = Pipeline([  # Create a machine learning pipeline.\n",
        "    (\"vectorizer\", CountVectorizer(stop_words='english', max_features=100)),  # Step 1: Convert text data into numerical features.\n",
        "    (\"predictor\", KNeighborsClassifier(n_neighbors=5))  # Step 2: Classify the data using K-Nearest Neighbors (KNN).\n",
        "])\n",
        "\n",
        "# Perform cross-validation to evaluate the model\n",
        "np.mean(cross_val_score(classifier, train_X, train_y, scoring=\"accuracy\"))\n",
        "# 'cross_val_score' performs k-fold cross-validation on the pipeline, calculating accuracy for each fold.\n",
        "# The 'np.mean()' function computes the average accuracy across all folds."
      ],
      "metadata": {
        "id": "0LZ4UFEVdSBd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = classifier['vectorizer'].fit_transform(train_X)\n",
        "# Extract the 'vectorizer' part from the pipeline using the key 'vectorizer'.\n",
        "# Then, fit and transform the training data (train_X) using the CountVectorizer.\n",
        "# 'fit' learns the vocabulary from the training data and 'transform' converts the text data into a document-term matrix (numeric features).\n",
        "\n",
        "X.shape\n",
        "# It gives you the number of rows (documents in train_X) and columns (the 100 most frequent features selected by CountVectorizer)."
      ],
      "metadata": {
        "id": "5-h-okpLdkxL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV"
      ],
      "metadata": {
        "id": "Pu_aIfiXdXF3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a new pipeline with CountVectorizer and KNeighborsClassifier\n",
        "classifierKNN = Pipeline([\n",
        "    (\"vectorizer\", CountVectorizer()),  # Step 1: Convert text data into numerical features using CountVectorizer.\n",
        "    (\"predictor\", KNeighborsClassifier())  # Step 2: Classify the data using K-Nearest Neighbors (KNN).\n",
        "])\n",
        "\n",
        "#HERE WE ACTUALLY SET THE HYPERPARAMETERS AS ASKED ABOVE\n",
        "# Create a dictionary of hyperparameters for tuning the pipeline's components (CountVectorizer and KNN).\n",
        "knn_param_grid = {\n",
        "    \"vectorizer__stop_words\": [None, \"english\"],  # Hyperparameter for removing stop words. (COUNT VECTORIZER)\n",
        "    \"vectorizer__ngram_range\": [(1, 1), (1, 2)],  # Hyperparameter for using unigrams or bigrams. (N-GRAM RANGE)\n",
        "    \"predictor__n_neighbors\": [3,5,7,9,10, 15, 20, 25, 30]  # Hyperparameter for the number of neighbors in KNN. (KNN CLASSIFIER)\n",
        "}\n",
        "\n",
        "\n",
        "# Create the GridSearchCV object which will search for the best hyperparameters based on cross-validated accuracy.\n",
        "knn_gs = GridSearchCV(classifierKNN, knn_param_grid, scoring=\"accuracy\")\n",
        "\n",
        "# Fit the model with the training data to find the best hyperparameters.\n",
        "knn_gs.fit(train_X, train_y)\n",
        "\n",
        "# Print the best hyperparameters and the best score found during the grid search.\n",
        "knn_gs.best_params_, knn_gs.best_score_\n"
      ],
      "metadata": {
        "id": "6J_7Y2zPdYeB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#FINAL ACCURACY\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "# Set the best hyperparameters from GridSearchCV into the classifier pipeline\n",
        "#TAKEN FROM GRID SEARCH ABOVE\n",
        "classifierKNN.set_params(**knn_gs.best_params_)\n",
        "\n",
        "# Fit the pipeline with the training data using the best parameters found\n",
        "classifierKNN.fit(train_X, train_y)\n",
        "\n",
        "# Calculate accuracy on the test set\n",
        "accuracy_score(test_y, classifierKNN.predict(test_X))\n",
        "\n",
        "\n",
        "#SAME AS LINE ONE ABOVE BUT IS MORE ROBUST AND RECCOMENDED\n",
        "classifierKNN = Pipeline([\n",
        "    (\"vectorizer\", CountVectorizer(ngram_range=(1,1), stop_words=None)),\n",
        "    (\"predictor\", KNeighborsClassifier(n_neighbors=30))\n",
        "])\n",
        "\n",
        "# Fit the pipeline with the training data\n",
        "classifierKNN.fit(train_X, train_y)\n",
        "\n",
        "# Calculate accuracy on the test set\n",
        "accuracy_score(test_y, classifierKNN.predict(test_X))"
      ],
      "metadata": {
        "id": "G8EYBZc3dcdh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Count Vectorizer & Decision Tree**"
      ],
      "metadata": {
        "id": "dlXqQReOdEkv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier"
      ],
      "metadata": {
        "id": "xby0f0ujdI7Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We can just create a preprocessor with a CountVectorizer in a pipeline with a decision tree.\n",
        "classifierDT = Pipeline([\n",
        "    (\"vectorizer\", CountVectorizer(stop_words='english', max_features=100)),\n",
        "    (\"predictor\", DecisionTreeClassifier())])\n",
        "\n",
        "# Get the validation error\n",
        "np.mean(cross_val_score(classifierDT, train_X, train_y, scoring=\"accuracy\"))"
      ],
      "metadata": {
        "id": "v9mgT5gDdm6V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's try some grid search\n",
        "classifierDT = Pipeline([\n",
        "    (\"vectorizer\", CountVectorizer()),\n",
        "    (\"predictor\", DecisionTreeClassifier())])\n",
        "\n",
        "# Create a dictionary of hyperparameters for the pipeline with a decision tree\n",
        "dt_param_grid = {\"vectorizer__stop_words\": [None, \"english\"],\n",
        "                 \"vectorizer__ngram_range\": [(1, 1), (1, 2)],\n",
        "                 \"predictor__criterion\": [\"gini\", \"entropy\"]}\n",
        "\n",
        "# Create the grid search object which will find the best hyperparameter values based on validation error\n",
        "dt_gs = GridSearchCV(classifierDT, dt_param_grid, scoring=\"accuracy\")\n",
        "\n",
        "# Run the GridSearchCV\n",
        "dt_gs.fit(train_X, train_y)\n",
        "\n",
        "# Print the best parameters and the score\n",
        "dt_gs.best_params_, dt_gs.best_score_"
      ],
      "metadata": {
        "id": "cV-im0b5dpyQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Retrain the model using the best hyperparameters found with GridSearchCV and compute the accuracy.\n",
        "classifierDT.set_params(**dt_gs.best_params_)\n",
        "classifierDT.fit(train_X, train_y)\n",
        "accuracy_score(test_y, classifierDT.predict(test_X))"
      ],
      "metadata": {
        "id": "isG6RRt9dsHQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifierDT = Pipeline([\n",
        "    (\"vectorizer\", CountVectorizer(ngram_range=(1,1), stop_words='english')),\n",
        "    (\"predictor\", DecisionTreeClassifier(criterion='gini'))])\n",
        "classifierDT.fit(train_X, train_y)\n",
        "accuracy_score(test_y, classifierDT.predict(test_X))"
      ],
      "metadata": {
        "id": "BmXeeiUddvM7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#PLOT TREE\n",
        "from sklearn.tree import plot_tree\n",
        "\n",
        "plt.figure(figsize=(20,10))\n",
        "plot_tree(classifierDT['predictor'], fontsize=10)\n",
        "plt.show()\n",
        "\n",
        "#MAKE VISIBLE\n",
        "plt.figure(figsize=(20,10))\n",
        "plot_tree(classifierDT['predictor'],  max_depth=3, fontsize=10)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "cy4wGoUXdwxs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#CHECK WORDS USED FIRST BY TAKING NUMBER SEEN FROM NODES IN PLOT TREE (X[...])\n",
        "classifierDT['vectorizer'].get_feature_names_out()[...]\n",
        "\n",
        "#ADD NAMES TO PLOT\n",
        "plt.figure(figsize=(20,10))\n",
        "plot_tree(classifierDT['predictor'],  max_depth=3, fontsize=10, feature_names=classifierDT['vectorizer'].get_feature_names_out())\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4nMxCclad2VO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dimensionality Reduction: SVD**"
      ],
      "metadata": {
        "id": "cEVjWTxndJUG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#SPARSITY\n",
        "#GIVES IDEA OF HOW SPARSE MATRIX IS\n",
        "#TYPICALLY IF DEALING WITH SPARSE MATRICES WE USING TRUNCATED SVD ONLY IF IT IMPROVES ACCCURACY\n",
        "print(\"Zero values:\", 100 - 554336/(4000*33358))"
      ],
      "metadata": {
        "id": "214I_OmwdM_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#TruncatedSVD: Reduces the dimensionality of the document-term matrix from potentially\n",
        "#thousands of features to just 200 features, improving computational efficiency while preserving the most important structure of the data.\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "\n",
        "dr = TruncatedSVD(n_components=200)\n",
        "X = dr.fit_transform(X)\n",
        "X\n"
      ],
      "metadata": {
        "id": "sT0O1Rn7eI9Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Decision Tree*"
      ],
      "metadata": {
        "id": "JxYLD7wKeOvN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Let's try some grid search\n",
        "classifierDTSVD = Pipeline([\n",
        "    (\"vectorizer\", CountVectorizer()),\n",
        "    (\"svd\", TruncatedSVD()),\n",
        "    (\"predictor\", DecisionTreeClassifier())])\n",
        "\n",
        "# Create a dictionary of hyperparameters for the pipeline with a decision tree\n",
        "dtsvd_param_grid = {\"vectorizer__stop_words\": [None, \"english\"],\n",
        "                    \"vectorizer__ngram_range\": [(1, 1), (1, 2)],\n",
        "                    \"svd__n_components\": [100, 200],\n",
        "                    \"predictor__criterion\": [\"gini\", \"entropy\"]\n",
        "                   }\n",
        "\n",
        "# Create the grid search object which will find the best hyperparameter values based on validation error\n",
        "dtsvd_gs = GridSearchCV(classifierDTSVD, dtsvd_param_grid, scoring=\"accuracy\")\n",
        "\n",
        "# Run the GridSearchCV\n",
        "dtsvd_gs.fit(train_X, train_y)\n",
        "\n",
        "# Print the best parameters and the score\n",
        "dtsvd_gs.best_params_, dtsvd_gs.best_score_"
      ],
      "metadata": {
        "id": "Sm8jgkRHeNiA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifierDTSVD.set_params(**dtsvd_gs.best_params_)\n",
        "classifierDTSVD.fit(train_X, train_y)\n",
        "accuracy_score(test_y, classifierDTSVD.predict(test_X))"
      ],
      "metadata": {
        "id": "aC8x63pteRvc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifierDTSVD = Pipeline([\n",
        "    (\"vectorizer\", CountVectorizer(stop_words='english', ngram_range=(1,2))),\n",
        "    (\"svd\", TruncatedSVD(n_components=200)),\n",
        "    (\"predictor\", DecisionTreeClassifier(criterion='entropy'))])\n",
        "\n",
        "classifierDTSVD.fit(train_X, train_y)\n",
        "accuracy_score(test_y, classifierDTSVD.predict(test_X))"
      ],
      "metadata": {
        "id": "mL1ehNY6eS8S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20,10))\n",
        "plot_tree(classifierDTSVD['predictor'],  max_depth=3, fontsize=10)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3Cjqo0J7eUVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*KNN*"
      ],
      "metadata": {
        "id": "cVOU3RAieVyT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Let's try some grid search\n",
        "classifierKNNSVD = Pipeline([\n",
        "    (\"vectorizer\", CountVectorizer()),\n",
        "    (\"svd\", TruncatedSVD()),\n",
        "    (\"predictor\", KNeighborsClassifier())])\n",
        "\n",
        "# Create a dictionary of hyperparameters for the pipeline with the KNN classifier\n",
        "knnsvd_param_grid = {\"vectorizer__stop_words\": [None, \"english\"],\n",
        "                     \"vectorizer__ngram_range\": [(1, 1), (1, 2)],\n",
        "                     \"svd__n_components\": [100, 200, 300, 400],\n",
        "                     \"predictor__n_neighbors\": [3,5,7,9,10, 15, 20, 25, 30]\n",
        "                    }\n",
        "\n",
        "# Create the grid search object which will find the best hyperparameter values based on validation error\n",
        "knnsvd_gs = GridSearchCV(classifierKNNSVD, knnsvd_param_grid, scoring=\"accuracy\")\n",
        "\n",
        "# Run the GridSearchCV\n",
        "knnsvd_gs.fit(train_X, train_y)\n",
        "\n",
        "# Print the best parameters and the score\n",
        "knnsvd_gs.best_params_, knnsvd_gs.best_score_"
      ],
      "metadata": {
        "id": "aqf8x6B1eWZN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "classifierKNNSVD.set_params(**knnsvd_gs.best_params_)\n",
        "classifierKNNSVD.fit(train_X, train_y)\n",
        "accuracy_score(test_y, classifierKNNSVD.predict(test_X))"
      ],
      "metadata": {
        "id": "Lanc-oNAeXuK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifierKNNSVD = Pipeline([\n",
        "    (\"vectorizer\", CountVectorizer(ngram_range=(1,1), stop_words='english')),\n",
        "    (\"svd\", TruncatedSVD(n_components=400)),\n",
        "    (\"predictor\", KNeighborsClassifier(n_neighbors=15))])\n",
        "\n",
        "classifierKNNSVD.fit(train_X, train_y)\n",
        "accuracy_score(test_y, classifierKNNSVD.predict(test_X))\n"
      ],
      "metadata": {
        "id": "OomktXireZ1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ADD TO JUSTIFICATIONS\n",
        "\n",
        "# Certainly! Let's break down the reasoning behind why the Decision Tree (DT) model might perform the best in this case, considering the context and the steps involved:\n",
        "\n",
        "# 1. Nature of the Decision Tree (DT) Model:\n",
        "# Non-Linear Decision Boundaries: Decision Trees are capable of creating complex, non-linear decision boundaries\n",
        "#by recursively splitting the data based on feature values. This can make them very powerful when the relationships between\n",
        "#the features and the target variable are complex and non-linear.\n",
        "\n",
        "# Handle Mixed Data Types: Decision Trees can handle both continuous and categorical data,\n",
        "#which makes them flexible. If your data has a mix of these, a Decision Tree can naturally handle it without needing much pre-processing.\n",
        "\n",
        "# Interpretability: Decision Trees are also interpretable, meaning you can visualize the tree structure and\n",
        "#see which features are most important for making predictions. This can provide insights into the relationships between the features and the target.\n",
        "\n",
        "\n",
        "# 2. Impact of Dimensionality Reduction (Truncated SVD):\n",
        "# Dimensionality Reduction Benefits: Truncated SVD reduces the number of features by capturing the most important components of the data.\n",
        "#This can help eliminate noise and reduce overfitting, making models more efficient.\n",
        "\n",
        "# Truncated SVD and Decision Trees: Decision Trees, by their nature, are quite good at handling high-dimensional data.\n",
        "\n",
        "#They tend to select the most important features through splits, and can still perform well even with a large number of features.\n",
        "\n",
        "#Truncated SVD may or may not improve the performance of Decision Trees, but if it does, it could be because the dimensionality reduction eliminated noise or redundant features that were not useful for the splits.\n",
        "# Why SVD May Not Help KNN: KNN is a distance-based model, and it relies on the similarity between instances in the feature space.\n",
        "\n",
        "#High-dimensional data can cause curse of dimensionality, meaning that as the number of features increases, the data becomes sparse,\n",
        "#and the distance between points becomes less meaningful. Truncated SVD can reduce the dimensionality,\n",
        "#which might improve KNN's performance by making the distance metric more useful, but it's not always guaranteed to do so.\n",
        "\n",
        "\n",
        "# 3. KNN and Dimensionality:\n",
        "# KNN's Sensitivity to High Dimensions: KNN is very sensitive to the curse of dimensionality.\n",
        "#When you have many features, KNN has a harder time distinguishing between data points because the \"distance\" between points\n",
        "#becomes less meaningful as the feature space expands. Thus, in some cases, applying Truncated SVD to reduce the dimensionality\n",
        "#can improve KNN's performance.\n",
        "\n",
        "# Why DT Might Be Better: Decision Trees, however, do not suffer from the curse of dimensionality in the same way KNN does.\n",
        "#They only split the data based on the most relevant features, and if the data is highly dimensional,\n",
        "#the tree can still focus on the features that matter most. This can lead to better performance, especially when there are many relevant features.\n",
        "\n",
        "# 4. Effect of Hyperparameter Tuning:\n",
        "# The best parameters found via grid search for Decision Trees may have contributed to their superior performance.\n",
        "#Decision Trees have several hyperparameters (e.g., max_depth, min_samples_split, criterion, etc.) that, when tuned,\n",
        "#can drastically improve their accuracy. If the grid search for DT resulted in a well-optimized model,\n",
        "#that could explain its higher accuracy compared to KNN.\n",
        "\n",
        "# 5. Overall Model Behavior:\n",
        "# The Decision Tree likely benefited from its ability to focus on the most informative features in the dataset.\n",
        "#The grid search helped fine-tune its hyperparameters, and it might have been better suited to the structure of your data,\n",
        "#leading to improved performance on the test set.\n",
        "\n",
        "# KNN might have struggled due to its reliance on distance metrics, especially if the data had many irrelevant or noisy features.\n",
        "#While Truncated SVD could have helped by reducing the dimensionality,\n",
        "#KNN may not have gained as much benefit from this reduction compared to Decision Trees.\n",
        "\n",
        "# Conclusion:\n",
        "# DT's success can be attributed to its ability to handle complex, non-linear relationships in the data, its flexibility with mixed data types,\n",
        "#and its robustness to high-dimensional spaces when compared to distance-based models like KNN.\n",
        "\n",
        "# KNN's lower performance, despite the use of Truncated SVD, suggests that the distance metric in high-dimensional spaces was still problematic,\n",
        "#even with dimensionality reduction.\n",
        "\n",
        "# The hyperparameter tuning also played a key role, as the grid search likely fine-tuned the\n",
        "#Decision Tree model to perform optimally for your specific data.\n",
        "\n",
        "# Ultimately, DT was the best choice in your case because it handled the complexity of the data more effectively than KNN,\n",
        "#especially after considering the performance metrics after applying Truncated SVD."
      ],
      "metadata": {
        "id": "_wZSMrIQefJP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **MOCK EXAM**"
      ],
      "metadata": {
        "id": "vf2zCU00er1z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Is train-test split stratified*"
      ],
      "metadata": {
        "id": "LFN7zqy5e-Lg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(df['target'].value_counts())\n",
        "#Proportion of value counts in target (alternative for below)\n",
        "print(df['target'].value_counts(normalize=True) * 100)\n",
        "\n",
        "print(test_df['target'].value_counts())\n",
        "print(test_df['target'].value_counts(normalize=True) * 100)\n",
        "\n",
        "\n",
        "# YOUR CODE HERE\n",
        "print(sum(df['target'] == 1)/(df.shape[0]) * 100)\n",
        "print(sum(test_df['target'] == 1)/(test_df.shape[0]) * 100)"
      ],
      "metadata": {
        "id": "zG_SyNlIeuPq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Machine Learning Pipeline & Hyperparametrization*"
      ],
      "metadata": {
        "id": "71zkjGzGgc-2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df[\"target\"].shape)\n",
        "print(test_df[\"target\"].shape)\n",
        "#The dimensions of the variables show lots of instances thus dimensionality reduction would be a good idea\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "#Want to normalize our values as we observe that some range from ... to .. thus we do this to avoid outliers from affecting our data\n",
        "#Here we use a classifier as the task asks that we classify either satisfiable or non-satisfiable\n",
        "classifierKNN = Pipeline([\n",
        "    (\"scaler\", MinMaxScaler()),\n",
        "    (\"predictor\", KNeighborsClassifier())\n",
        "])\n",
        "\n",
        "\n",
        "#Set a parameter grid referencing the pipeline\n",
        "#Set range of k neighbours\n",
        "knn_param_grid = {\n",
        "    \"predictor__n_neighbors\": [3,5,7,9,10,15,20,25,30],\n",
        "    \"predictor__p\": [1, 2]}\n",
        "\n",
        "\n",
        "# Create the GridSearchCV object which will search for the best hyperparameters based on cross-validated accuracy.\n",
        "knn_gs = GridSearchCV(classifierKNN, knn_param_grid, scoring=\"accuracy\")\n",
        "\n",
        "# Fit the model with the training data to find the best hyperparameters.\n",
        "knn_gs.fit(df.loc[:, :\"rwh_2_max\"], df[\"target\"])\n",
        "\n",
        "# Print the best hyperparameters and the best score found during the grid search.\n",
        "knn_gs.best_params_, knn_gs.best_score_\n"
      ],
      "metadata": {
        "id": "11Od7eQGgoMc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Evalute model in test set & baseline classifier*"
      ],
      "metadata": {
        "id": "j_sWN-2lgtfa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Here we set a baseline classifier as a reference point for our model seen above\n",
        "#Thus any test accuracy in the model that is lower than this refernce percentage indicates poor accuracy\n",
        "print((test_df[\"target\"] == 0).mean())\n",
        "print((test_df[\"target\"] == 1).mean())\n",
        "\n",
        "\n",
        "# Set the best hyperparameters from GridSearchCV into the classifier pipeline\n",
        "#TAKEN FROM GRID SEARCH ABOVE\n",
        "classifierKNN.set_params(**knn_gs.best_params_)\n",
        "# Fit the pipeline with the training data using the best parameters found\n",
        "classifierKNN.fit(df.loc[:, :\"rwh_2_max\"], df[\"target\"])\n",
        "# Calculate accuracy on the test set\n",
        "accuracy_score(test_df[\"target\"], classifierKNN.predict(test_df.loc[:, :\"rwh_2_max\"]))"
      ],
      "metadata": {
        "id": "YrNr-_TMgvur"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}